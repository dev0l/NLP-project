{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"unigram_freq.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>23135851162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>of</td>\n",
       "      <td>13151942776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and</td>\n",
       "      <td>12997637966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to</td>\n",
       "      <td>12136980858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "      <td>9081174698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  word        count\n",
       "0  the  23135851162\n",
       "1   of  13151942776\n",
       "2  and  12997637966\n",
       "3   to  12136980858\n",
       "4    a   9081174698"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = dataset.iloc[:, :1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = dataset.iloc[:, 1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23135851162 13151942776 12997637966 12136980858  9081174698  8469404971\n",
      "  5933321709  4705743816  3750423199  3400031103  3350048871  3228469771\n",
      "  3183110675  3086225277  2996181025  2813163874  2633487141  2590739907\n",
      "  2398724162  2393614870]\n"
     ]
    }
   ],
   "source": [
    "print(counts[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = dataset.iloc[2,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and\n"
     ]
    }
   ],
   "source": [
    "print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "longstring = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 100000):\n",
    "    longstring += str(dataset.iloc[i,0]) + \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "811707\n"
     ]
    }
   ],
   "source": [
    "print(len(longstring))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en import English\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longstring "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(longstring)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "within ADP 85 prep\n",
      "states NOUN 92 compound\n",
      "area NOUN 92 pobj\n",
      "want VERB 100 advcl\n",
      "phone NOUN 92 compound\n",
      "dvd NOUN 92 compound\n",
      "shipping NOUN 92 nmod\n",
      "reserved VERB 100 amod\n",
      "subject NOUN 92 dobj\n",
      "between ADP 85 prep\n",
      "forum NOUN 92 compound\n",
      "family NOUN 92 compound\n",
      "l NOUN 92 pobj\n",
      "long ADV 86 advmod\n",
      "based VERB 100 prep\n",
      "w ADP 85 prep\n",
      "code NOUN 92 compound\n",
      "show NOUN 92 nmod\n",
      "o INTJ 91 nmod\n",
      "even ADV 86 advmod\n",
      "black ADJ 84 amod\n",
      "check NOUN 92 nmod\n",
      "special ADJ 84 amod\n",
      "prices NOUN 92 compound\n",
      "website NOUN 92 compound\n",
      "index NOUN 92 pobj\n",
      "being VERB 100 advcl\n",
      "women NOUN 92 nsubj\n",
      "much ADJ 84 advmod\n",
      "sign VERB 100 ccomp\n",
      "file NOUN 92 compound\n",
      "link NOUN 92 dobj\n",
      "open ADJ 84 amod\n",
      "today NOUN 92 npadvmod\n",
      "technology NOUN 92 nmod\n",
      "south ADJ 84 amod\n",
      "case NOUN 92 nmod\n",
      "project NOUN 92 nmod\n",
      "same ADJ 84 amod\n",
      "pages NOUN 92 dobj\n",
      "uk PROPN 96 compound\n",
      "version NOUN 92 compound\n",
      "section NOUN 92 dobj\n",
      "own VERB 100 advcl\n",
      "found VERB 100 conj\n",
      "sports NOUN 92 compound\n",
      "house NOUN 92 npadvmod\n",
      "related VERB 100 amod\n",
      "security NOUN 92 dobj\n",
      "both DET 90 preconj\n",
      "g NOUN 92 nmod\n",
      "county NOUN 92 nmod\n",
      "american ADJ 84 amod\n",
      "photo NOUN 92 compound\n",
      "game NOUN 92 compound\n",
      "members NOUN 92 compound\n",
      "power NOUN 92 appos\n",
      "while SCONJ 98 mark\n",
      "care NOUN 92 advcl\n",
      "network NOUN 92 dobj\n",
      "down ADP 85 prep\n",
      "computer NOUN 92 compound\n",
      "systems NOUN 92 pobj\n",
      "three NUM 93 nummod\n",
      "total ADJ 84 amod\n",
      "place NOUN 92 compound\n",
      "end NOUN 92 npadvmod\n",
      "following VERB 100 prep\n",
      "download NOUN 92 pobj\n",
      "h INTJ 91 intj\n",
      "him PRON 95 nsubj\n",
      "without ADP 85 prep\n",
      "per ADP 85 prep\n",
      "access NOUN 92 pobj\n",
      "think VERB 100 ROOT\n",
      "north ADJ 84 amod\n",
      "resources NOUN 92 nmod\n",
      "current ADJ 84 amod\n",
      "posts NOUN 92 ccomp\n",
      "big ADJ 84 amod\n",
      "media NOUN 92 compound\n",
      "law NOUN 92 compound\n",
      "control NOUN 92 compound\n",
      "water NOUN 92 compound\n",
      "history NOUN 92 compound\n",
      "pictures NOUN 92 appos\n",
      "size VERB 100 ccomp\n",
      "art NOUN 92 compound\n",
      "personal NOUN 92 dobj\n",
      "since SCONJ 98 prep\n",
      "including VERB 100 pcomp\n",
      "guide NOUN 92 compound\n",
      "shop NOUN 92 compound\n",
      "directory NOUN 92 compound\n",
      "board NOUN 92 compound\n",
      "location NOUN 92 dobj\n",
      "change VERB 100 ccomp\n",
      "white ADJ 84 amod\n",
      "text NOUN 92 compound\n",
      "small ADJ 84 amod\n",
      "rating NOUN 92 compound\n",
      "rate NOUN 92 compound\n",
      "government NOUN 92 compound\n",
      "children NOUN 92 dobj\n",
      "during ADP 85 prep\n",
      "usa NOUN 92 compound\n",
      "return NOUN 92 compound\n",
      "students NOUN 92 pobj\n",
      "v ADP 85 prep\n",
      "shopping NOUN 92 compound\n",
      "account NOUN 92 pobj\n",
      "times NOUN 92 npadvmod\n",
      "sites NOUN 92 nsubj\n",
      "level VERB 100 conj\n",
      "digital ADJ 84 amod\n",
      "profile NOUN 92 nmod\n",
      "previous ADJ 84 amod\n",
      "form NOUN 92 compound\n",
      "events NOUN 92 nsubj\n",
      "love VERB 100 ccomp\n",
      "old ADJ 84 amod\n",
      "john NOUN 92 compound\n",
      "main ADJ 84 amod\n",
      "call NOUN 92 compound\n",
      "hours NOUN 92 compound\n",
      "image NOUN 92 compound\n",
      "department NOUN 92 compound\n",
      "title NOUN 92 compound\n",
      "description NOUN 92 dobj\n",
      "non ADJ 84 nmod\n",
      "k X 101 nmod\n",
      "y PROPN 96 compound\n",
      "insurance NOUN 92 dobj\n",
      "another DET 90 dobj\n",
      "why ADV 86 advcl\n",
      "shall AUX 87 punct\n",
      "property NOUN 92 compound\n",
      "class NOUN 92 compound\n",
      "cd NOUN 92 nsubj\n",
      "still ADV 86 advmod\n",
      "money NOUN 92 compound\n",
      "quality NOUN 92 appos\n",
      "every DET 90 det\n",
      "listing NOUN 92 amod\n",
      "content NOUN 92 compound\n",
      "country NOUN 92 nmod\n",
      "private ADJ 84 amod\n",
      "little ADJ 84 amod\n",
      "visit NOUN 92 nsubj\n",
      "save VERB 100 ccomp\n"
     ]
    }
   ],
   "source": [
    "for i in range (250, 400):\n",
    "    #if nlp.vocab.strings[doc[i].pos_] == 87:\n",
    "        print(doc[i].text, doc[i].pos_, nlp.vocab.strings[doc[i].pos_], doc[i].dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "### arrays to dataset: counts\n",
    "\n",
    "words = []\n",
    "pos = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0, len(doc)):\n",
    "    words.append(doc[i].text)\n",
    "    pos.append(nlp.vocab.strings[doc[i].pos_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df100k = pd.DataFrame(list(zip(words, counts, pos)), \n",
    "               columns =[\"word\", \"frequency\", \"pos\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
